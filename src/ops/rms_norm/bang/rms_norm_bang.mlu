#include "bang.h"
#include "cnrt.h"
#include "rms_norm_bang.h"
#include "../../../devices/bang/common_bang.h"


const int SRC_MAX_SIZE = 1024 * 64;//尽量取大一些
__nram__  char nram_buffer[NRAM_MAX_SIZE];
template<typename T>
__mlu_global__ void rms_norm(T *destination, T const *source, float const *weight, int stride_y, int stride_x, float eps, int othersize, int dimsize, int dimS){
    const int maxNum = SRC_MAX_SIZE/sizeof(float);
    int wSize = 128 / sizeof(T);

    int remainT = othersize % taskDim;
    int stepEasy = (othersize - remainT) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remainT ? stepHard : stepEasy);
    int indStart = (taskId < remainT ? taskId * stepHard : (taskId - remainT) * stepEasy + remainT * stepHard);

    if(dimsize >= maxNum){
        
        char *nram_buffer1 = nram_buffer + (2 * maxNum + 3 * wSize) * sizeof(T);
        T *src = (T *)nram_buffer;//[maxNum]
        T *wet = src + maxNum;//[maxNum]
        T *destSumFinal = wet + maxNum;//[wSize]
        T *destSum = destSumFinal + wSize;//[wSize]
        T *srcTmp = destSum + wSize;//[wSize]
        __bang_write_zero(srcTmp, wSize);
        float *wetTmp = (float *)nram_buffer1;

        int remain = dimsize % maxNum;
        int repeat = (dimsize - remain) / maxNum;
        int segNum = maxNum / wSize;//准备数值求和

        for(int i = indStart; i < indStart + step; i++){
            int inds = 0;
            int indd = 0;
            int indi = i;
            inds += (indi % othersize) * stride_x;
            indd += (indi % othersize) * stride_y;
            __bang_write_zero(destSumFinal, wSize);
            __bang_write_zero(destSum, wSize);
            for(int s = 0; s < repeat; s++){
                __memcpy(src, source + inds + s * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, src, maxNum);//src = src * src
                
                if(maxNum >= wSize){
                    for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                        for(int j = 0; j < strip; j++){
                            __bang_add(src + j * wSize, src + j * wSize, src + (j + strip) * wSize, wSize);
                        }
                    }
                    __bang_reduce_sum(destSum, src, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
                else{
                    __memcpy(srcTmp, src, maxNum * sizeof(T), NRAM2NRAM);
                    __bang_reduce_sum(destSum, srcTmp, wSize);
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
            }
            if(remain){
                __bang_write_zero(src, maxNum);
                __bang_write_zero(destSum, wSize);
                __memcpy(src, source + inds + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, src, maxNum);//src = src * src
                if(maxNum >= wSize){
                    for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                        for(int j = 0; j < strip; j++){
                            __bang_add(src + j * wSize, src + j * wSize, src + (j + strip) * wSize, wSize);
                        }
                    }
                    __bang_reduce_sum(destSum, src, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
                else{
                    __memcpy(srcTmp, src, remain * sizeof(T), NRAM2NRAM);
                    __bang_reduce_sum(destSum, srcTmp, wSize);
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
            }
            destSumFinal[0] /= dimsize;
            destSumFinal[0] += eps;
            destSumFinal[0] = pow(destSumFinal[0], 0.5);
            T globalSumInv = 1.0 / destSumFinal[0];
            for(int s = 0; s < repeat; s++){
                __memcpy(src, source + inds + s * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
                __memcpy(wetTmp, weight + s * maxNum, maxNum * sizeof(float), GDRAM2NRAM);
                __bang_float2half_dn(wet, wetTmp, maxNum);
                __bang_mul(src, src, wet, maxNum);//src = src * wet
                __bang_mul_scalar(src, src, globalSumInv, maxNum);
                __memcpy(destination + indd + s * maxNum, src, maxNum * sizeof(T), NRAM2GDRAM);
            }
            if(remain){
                __memcpy(src, source + inds + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
                __memcpy(wetTmp, weight + repeat * maxNum, remain * sizeof(float), GDRAM2NRAM);
                __bang_float2half_dn(wet, wetTmp, maxNum);
                __bang_mul(src, src, wet, maxNum);//src = src * wet
                __bang_mul_scalar(src, src, globalSumInv, maxNum);
                __memcpy(destination + indd + repeat * maxNum, src, remain * sizeof(T), NRAM2GDRAM);
            }
        }
    }
    else{
        char *nram_buffer1 = nram_buffer + (2 * dimsize + 2 * wSize + dimS) * sizeof(T);
        T *src = (T *)nram_buffer;//[dimsize]
        T *wet = src + dimsize;//[dimsize]
        T *destSumFinal = wet + dimsize;//[wSize]
        T *destSum = destSumFinal + wSize;//[dimS]
        T *srcTmp = destSum + dimS;
        __bang_write_zero(srcTmp, wSize);
        float *wetTmp = (float *)nram_buffer1;

        
        int segNum = dimS / wSize;

        for(int i = indStart; i < indStart + step; i++){
            __bang_write_zero(destSum, dimS);
            __bang_write_zero(destSumFinal, wSize);
            int inds = 0;
            int indd = 0;
            int indi = i;
            inds += (indi % othersize) * stride_x;
            indd += (indi % othersize) * stride_y;
            __memcpy(src, source + inds, dimsize * sizeof(T), GDRAM2NRAM);
            __bang_mul(destSum, src, src, dimsize);//src = src * src
            if(dimS >= wSize){
                for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                    for(int j = 0; j < strip; j++){
                        __bang_add(destSum + j * wSize, destSum + j * wSize, destSum + (j + strip) * wSize, wSize);
                    }
                }
                __bang_reduce_sum(destSumFinal, destSum, wSize);
            }
            else{
                __memcpy(srcTmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
                __bang_reduce_sum(destSumFinal, srcTmp, wSize);
            }
            destSumFinal[0] /= dimsize;
            destSumFinal[0] += eps;
            destSumFinal[0] = pow(destSumFinal[0], 0.5);
            T globalSumInv = 1.0 / destSumFinal[0];
            __memcpy(wetTmp, weight, dimsize * sizeof(float), GDRAM2NRAM);
            __bang_float2half_dn(wet, wetTmp, dimsize);
            __bang_mul(src, src, wet, dimsize);//src = src * wet
            __bang_mul_scalar(src, src, globalSumInv, dimsize);
            __memcpy(destination + indd, src, dimsize * sizeof(T), NRAM2GDRAM);
        }
    }
}

template<typename T>
__mlu_global__ void rms_norm(T *destination, T const *source, T const *weight, int stride_y, int stride_x, float eps, int othersize, int dimsize, int dimS){
    const int maxNum = SRC_MAX_SIZE/sizeof(T);
    int wSize = 128 / sizeof(T);

    int remainT = othersize % taskDim;
    int stepEasy = (othersize - remainT) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remainT ? stepHard : stepEasy);
    int indStart = (taskId < remainT ? taskId * stepHard : (taskId - remainT) * stepEasy + remainT * stepHard);
    
    if(dimsize >= maxNum){
        
        T *src = (T *)nram_buffer;//[maxNum]
        T *wet = src + maxNum;//[maxNum]
        T *destSumFinal = wet + maxNum;//[wSize]
        T *destSum = destSumFinal + wSize;//[wSize]
        T *srcTmp = destSum + wSize;//[wSize]
        __bang_write_zero(srcTmp, wSize);

        int remain = dimsize % maxNum;
        int repeat = (dimsize - remain) / maxNum;
        int segNum = maxNum / wSize;//准备数值求和

        for(int i = indStart; i < indStart + step; i++){
            int inds = 0;
            int indd = 0;
            int indi = i;
            inds += (indi % othersize) * stride_x;
            indd += (indi % othersize) * stride_y;
            __bang_write_zero(destSumFinal, wSize);
            __bang_write_zero(destSum, wSize);
            for(int s = 0; s < repeat; s++){
                __memcpy(src, source + inds + s * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, src, maxNum);//src = src * src
                
                if(maxNum >= wSize){
                    for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                        for(int j = 0; j < strip; j++){
                            __bang_add(src + j * wSize, src + j * wSize, src + (j + strip) * wSize, wSize);
                        }
                    }
                    __bang_reduce_sum(destSum, src, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
                else{
                    __memcpy(srcTmp, src, maxNum * sizeof(T), NRAM2NRAM);
                    __bang_reduce_sum(destSum, srcTmp, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
            }
            if(remain){
                __bang_write_zero(src, maxNum);
                __bang_write_zero(destSum, wSize);
                __memcpy(src, source + inds + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, src, maxNum);//src = src * src
                if(maxNum >= wSize){
                    for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                        for(int j = 0; j < strip; j++){
                            __bang_add(src + j * wSize, src + j * wSize, src + (j + strip) * wSize, wSize);
                        }
                    }
                    __bang_reduce_sum(destSum, src, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
                else{
                    __memcpy(srcTmp, src, remain * sizeof(T), NRAM2NRAM);
                    __bang_reduce_sum(destSum, srcTmp, wSize);//此时destSum[0]保存的就是当前maxNum长度数据的数值和
                    __bang_add(destSumFinal, destSumFinal, destSum, wSize);
                }
            }
            destSumFinal[0] /= dimsize;
            destSumFinal[0] += eps;
            destSumFinal[0] = pow(destSumFinal[0], 0.5);
            T globalSumInv = 1.0 / destSumFinal[0];
            for(int s = 0; s < repeat; s++){
                __memcpy(src, source + inds + s * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
                __memcpy(wet, weight + s * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, wet, maxNum);//src = src * wet
                __bang_mul_scalar(src, src, globalSumInv, maxNum);
                __memcpy(destination + indd + s * maxNum, src, maxNum * sizeof(T), NRAM2GDRAM);
            }
            if(remain){
                __memcpy(src, source + inds + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
                __memcpy(wet, weight + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
                __bang_mul(src, src, wet, maxNum);//src = src * wet
                __bang_mul_scalar(src, src, globalSumInv, maxNum);
                __memcpy(destination + indd + repeat * maxNum, src, remain * sizeof(T), NRAM2GDRAM);
            }
        }
    }
    else{
        
        T *src = (T *)nram_buffer;//[dimsize]
        T *wet = src + dimsize;//[dimsize]
        T *destSumFinal = wet + dimsize;//[wSize]
        T *destSum = destSumFinal + wSize;//[dimS]
        T *srcTmp = destSum + dimS;//[wSize]

        
        int segNum = dimS / wSize;

        for(int i = indStart; i < indStart + step; i++){
            __bang_write_zero(destSum, dimS);
            __bang_write_zero(destSumFinal, wSize);
            int inds = 0;
            int indd = 0;
            int indi = i;
            inds += (indi % othersize) * stride_x;
            indd += (indi % othersize) * stride_y;
            __memcpy(src, source + inds, dimsize * sizeof(T), GDRAM2NRAM);
            __bang_mul(destSum, src, src, dimsize);//src = src * src
            if(dimS >= wSize){
                for(int strip = segNum / 2; strip > 0; strip = strip / 2){
                    for(int j = 0; j < strip; j++){
                        __bang_add(destSum + j * wSize, destSum + j * wSize, destSum + (j + strip) * wSize, wSize);
                    }
                }
                __bang_reduce_sum(destSumFinal, destSum, wSize);
            }
            else{
                __memcpy(srcTmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
                __bang_reduce_sum(destSumFinal, srcTmp, wSize);
                
            }
            destSumFinal[0] /= dimsize;
            destSumFinal[0] += eps;
            destSumFinal[0] = pow(destSumFinal[0], 0.5);
            T globalSumInv = 1.0 / destSumFinal[0];
            __memcpy(wet, weight, dimsize * sizeof(T), GDRAM2NRAM);
            __bang_mul(src, src, wet, dimsize);//src = src * wet
            __bang_mul_scalar(src, src, globalSumInv, dimsize);
            __memcpy(destination + indd, src, dimsize * sizeof(T), NRAM2GDRAM);
        }
    }
}


template<typename T, typename Tw>
void rms_normUnion(cnrtQueue_t queue, T *y, T const *x, Tw const *w, int stride_y, int stride_x, float epsilon, int n, int d){
    cnrtDim3_t k_dim;
    cnrtFunctionType_t k_type;

    k_dim.x = 4;
    k_dim.y = 1;
    k_dim.z = 1;
    k_type = CNRT_FUNC_TYPE_UNION1;
    int dimS;
    float mi = log2(d);
    if (floor(mi) == mi) {
        dimS = d;
    } else {
        dimS = pow(2, floor(mi) + 1);
    }
    rms_norm<T><<<k_dim, k_type, queue>>>(y, x, w, stride_y, stride_x, epsilon, n, d, dimS);
    cnrtQueueSync(queue);

}
void rms_norm_bang_f16(RMSNormBangDescriptor_t desc, void *y, void const *x, void const *w,
                             void *stream){
    auto queue = reinterpret_cast<cnrtQueue_t>(stream);                            
    int n = static_cast<int>(desc->n);
    int d = static_cast<int>(desc->d);
    auto y_ = reinterpret_cast<half *>(y);
    auto x_ = reinterpret_cast<half const *>(x);
    auto epsilon = desc->epsilon;//float

    // Get strides in terms of elements
    int stride_y = static_cast<int>(desc->stride_y);
    int stride_x = static_cast<int>(desc->stride_x);
    auto w_datatype = desc->w_datatype;
    if (dtype_eq(w_datatype, F16)) {
        auto w_ = reinterpret_cast<half const *>(w);
        rms_normUnion<half, half>(queue, y_, x_, w_, stride_y, stride_x, epsilon, n, d);
    }
    else{
        auto w_ = reinterpret_cast<float const *>(w);
        rms_normUnion<half, float>(queue, y_, x_, w_, stride_y, stride_x, epsilon, n, d);
    }
    
}
infiniopStatus_t bangRMSNorm(RMSNormBangDescriptor_t desc,
                             void *workspace,
                             unsigned long int workspace_size,
                             void *y, void const *x, void const *w,
                             void *stream){
    if (cnrtSetDevice(desc->device_id) != cnrtSuccess) {
        return STATUS_BAD_DEVICE;
    }
    if (dtype_eq(desc->dtype, F16)){
        rms_norm_bang_f16(desc, y, x, w, stream);
        return STATUS_SUCCESS;
    }

    return STATUS_BAD_TENSOR_DTYPE;
}
